{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "#from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import svd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceIterator:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "    def __iter__(self):\n",
    "        with open(self.filename, 'r') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                yield line.strip(\"\\n\").split(\" \")\n",
    "                if i == 100000:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator_1 = SentenceIterator(\"../semeval2020_ulscd_swe/corpus1/lemma/kubhist2a.txt\")\n",
    "iterator_2 = SentenceIterator(\"../semeval2020_ulscd_swe/corpus2/lemma/kubhist2b.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = gensim.models.Word2Vec(iterator_1, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.save(\"../models/model_old.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = gensim.models.Word2Vec(iterator_2, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.save(\"../models/model_new.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the models here if you already have computed embeddings and saved the models\n",
    "#model_1 = Word2Vec.load(\"../models/model_old.model\")\n",
    "#model_2 = Word2Vec.load(\"../models/model_new.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = list(set(model_1.wv.key_to_index.keys()).intersection(set(model_2.wv.key_to_index.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align matrices using the orthogonal procrustes procedure\n",
    "def align_matrices(A, B):\n",
    "    u, sigma, vT = svd(np.matmul(A, B.transpose()), full_matrices=False)\n",
    "    R = np.matmul(vT.transpose(), u.transpose())\n",
    "    A_new = np.matmul(R, A)\n",
    "    return A_new, B\n",
    "\n",
    "def align_embeddings(emb_1, emb_2):\n",
    "    emb1_new, _ = align_matrices(emb_1.transpose(),emb_2.transpose())\n",
    "    return emb1_new.transpose(), emb_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_embs_1 = np.array([model_1.wv[word] for word in common_words])\n",
    "common_embs_2 = np.array([model_2.wv[word] for word in common_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_vectors, _ = align_embeddings(common_embs_1, common_embs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dict_1 = {}\n",
    "emb_dict_2 = {}\n",
    "for i, word in enumerate(common_words):\n",
    "    emb_dict_1[word] = rotated_vectors[i]\n",
    "    emb_dict_2[word] = common_embs_2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = {}\n",
    "for word in common_words:\n",
    "    similarities[word] = cosine_similarity(emb_dict_1[word].reshape(1,-1),emb_dict_2[word].reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_similarity = sorted(similarities.items(), key = lambda x : x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stälia', -0.3606568),\n",
       " ('1319', -0.31230494),\n",
       " ('börre', -0.29665688),\n",
       " ('chans', -0.2856727),\n",
       " ('agia', -0.28157967),\n",
       " ('bemåla', -0.25456107),\n",
       " ('fattet', -0.25157046),\n",
       " ('golli', -0.24208164),\n",
       " ('tolli', -0.2381638),\n",
       " ('egga', -0.23287061),\n",
       " ('klädtorkning', -0.22133023),\n",
       " ('ssal', -0.22058086),\n",
       " ('iean', -0.20308968),\n",
       " ('källsta', -0.1919604),\n",
       " ('nymålning', -0.18984091),\n",
       " ('licence', -0.1897186),\n",
       " ('åfwen', -0.18690658),\n",
       " ('mohn', -0.1854572),\n",
       " ('ennis', -0.18218979),\n",
       " ('köna', -0.18187992)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_by_similarity[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_most_similar(model_1, model_2, word):\n",
    "    most_similar_1 = model_1.wv.most_similar(word)\n",
    "    most_similar_2 = model_2.wv.most_similar(word)\n",
    "    print(\"\\t Model 1 \\t\\tModel 2\")\n",
    "    for i in range(min(len(most_similar_1),len(most_similar_2))):\n",
    "        print(f\"{i}\\t{most_similar_1[i][0]}: {most_similar_1[i][1]:.3f}\\t\\t{most_similar_2[i][0]}: {most_similar_2[i][1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Model 1 \t\tModel 2\n",
      "0\tslockholm: 0.873\t\tgöteborg: 0.856\n",
      "1\tstockbolm: 0.821\t\tslockholm: 0.822\n",
      "2\tgötheborg: 0.789\t\tnorrköping: 0.812\n",
      "3\tnorrköping: 0.782\t\törebro: 0.763\n",
      "4\tstockdolm: 0.781\t\tmalmö: 0.759\n",
      "5\tstockholn: 0.747\t\tjönköping: 0.742\n",
      "6\törebro: 0.738\t\tupsala: 0.742\n",
      "7\tcarlskrona: 0.731\t\thelsingfors: 0.734\n",
      "8\tstockhol: 0.730\t\tlinköping: 0.732\n",
      "9\tjönköping: 0.714\t\thelsingborg: 0.712\n"
     ]
    }
   ],
   "source": [
    "compare_most_similar(model_1, model_2, \"stockholm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
